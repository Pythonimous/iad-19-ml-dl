{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2OKm3caoSt0d",
    "outputId": "93048f65-547a-4bb6-bd03-c019a8a968de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LneQv3AkeD0k"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import collections\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XKBysLtJf9HR"
   },
   "outputs": [],
   "source": [
    "os.chdir('gdrive/My Drive/hotdog_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I7cQGoOtgF_Y",
    "outputId": "fcbbad0d-769d-4620-f4da-a562cb77bdfd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 708/708 [00:03<00:00, 212.23it/s]\n"
     ]
    }
   ],
   "source": [
    "image_list = []\n",
    "for filename in tqdm(glob.glob('train/hotdog/*.jpg')):\n",
    "    im = Image.open(filename).convert('RGB')  # in case some are grayscale\n",
    "    image_list.append((im, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8q5itu5Ghj0n",
    "outputId": "f6890b73-5ad8-4aaa-e1de-8e60c2021edb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 963/963 [00:04<00:00, 204.11it/s]\n"
     ]
    }
   ],
   "source": [
    "for filename in tqdm(glob.glob('train/not_hotdog/*.jpg')):\n",
    "    im = Image.open(filename).convert('RGB')\n",
    "    image_list.append((im, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9SN9AbynExx"
   },
   "outputs": [],
   "source": [
    "image_list = [(item[0].rotate(90, expand=True),item[1]) if item[0].size[0]<item[0].size[1] else item for item in image_list]\n",
    "image_list = [(item[0].resize((224,224)),item[1]) for item in image_list]  # нужный размер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "87KrIwoFhTz6"
   },
   "outputs": [],
   "source": [
    "X_train = [np.array(item[0]) for item in image_list]\n",
    "y_train = [item[1] for item in image_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fVcgW2orpVnx"
   },
   "source": [
    "# Задание 3. VGG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wq1n02XGMnu-"
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train).reshape(1671,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZHWXe9yZMwGO"
   },
   "outputs": [],
   "source": [
    "X_train = [image.reshape(1, 224, 224, 3) for image in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMFnabFqUdRX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q8gt8rat8Nny"
   },
   "outputs": [],
   "source": [
    "X_train = [preprocess_input(image) for image in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "colab_type": "code",
    "id": "IrHAsLFx6dVa",
    "outputId": "03100c29-01d7-4208-fb10-25f535c48efc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelvgg = VGG16(weights='imagenet')\n",
    "modelvgg.layers.pop()\n",
    "modelvgg = Model(inputs=modelvgg.inputs, outputs=modelvgg.layers[-2].output)\n",
    "modelvgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RuGY2nzL6oDS"
   },
   "outputs": [],
   "source": [
    "X_train_vgg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jYSybRmu7M_u",
    "outputId": "04fbabb4-f7ea-4976-c9b2-b6f7bd387fff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [00:47<00:00, 35.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for image in tqdm(X_train):\n",
    "    X_train_vgg.append(modelvgg.predict(image).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvq4GCWo901V"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ad9WAyyAsB_m"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IjAJx2ilOCWT"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NMazJzFCORpz",
    "outputId": "63e301ad-ad72-477d-b9e1-2d6e3312a4a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1336, 4096), (1336, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AkYVBevh-PGp"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x6bMIek4-aqX"
   },
   "outputs": [],
   "source": [
    "linear_classifier = LinearSVC(random_state=seed, tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "tNUJN-vu-n8o",
    "outputId": "d8a288ce-9e3f-4057-9995-683c0557b5b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=42, tol=1e-05,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LQZO4V88-qmI",
    "outputId": "88209dbb-5596-4be2-8d2f-e5a24d844b16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9731343283582089"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIxGIXI__BKX"
   },
   "source": [
    "Линейный SVC на фичах из VGG16 показал точность в 97.3% (ошибка всего в ~0.027). Высокий результат ожидаем, поскольку ImageNet - один из классических (сейчас) подходов к классификации изображений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OSfFOWchAJnL"
   },
   "source": [
    "Важно заметить, что SVM, а также случайный лес и gradient boosting trees, хотя и обучаются на RGB-векторах ОЧЕНЬ долго из за их огромной длины, показывают результат гораздо хуже неоткалиброванной CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xUeOMxU_BMLg"
   },
   "source": [
    "Результат свёрточной нейронной сети гораздо лучше SVM даже при небольшой выборке, однако у нас будет слишком мало данных, чтобы превзойти ImageNet, даже при аугментации. Результат, безусловно, можно было бы улучшить подбором параметров, различными техниками нормализации, и т.д., но нам бы не удалось достичь результата ImageNet-конфигурации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mEnKVbfyCE9T"
   },
   "source": [
    "Выходы с предпоследнего слоя ImageNet, в свою очередь, малоразмерны (4096 в противовес нескольким сотням тысяч, как было в первой части), что позволяет эффективно использовать LinearSVC и сэкономить время на обучении. Более того, сеть уже обучена на большем количестве данных, чем мы когда-либо могли бы собрать; а представление изображений в виде векторов с предпоследнего слоя занимает уже немного времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqFQyfi1CkmU"
   },
   "source": [
    "Таким образом, в условии ограниченного объёма данных, временных (учитывая Runtime Google Colab :D) и аппаратных ресурсов, ImageNet + LinearSVM мне кажется наиболее перспективным для данной задачи из обозначенных подходов; его и будем улучшать."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Nikolaev 1.3 ImageNet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
