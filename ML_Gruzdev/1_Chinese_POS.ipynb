{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "1 Chinese POS.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "poTzBVcTCpJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1d3896c4-fcf6-4df9-9960-be6b49c6782a"
      },
      "source": [
        "!pip3 install conllu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: conllu in /usr/local/lib/python3.6/dist-packages (2.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLYzNJ1LCQy-",
        "colab_type": "text"
      },
      "source": [
        "## Фичи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk-69H-oCQzD",
        "colab_type": "text"
      },
      "source": [
        "В первую очередь используем иероглифы, которые, как известно, имеют в себе семантический компонент, и, таким образом, являются значимыми признаками. Список иероглифов извлечём с http://www.hanzicraft.com/lists/frequency - там 8943 наиболее распространённых иероглифов. (в Python своего встроенного списка нет)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUWStIoCCQzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "sess = requests.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Bgr0sgUCQzP",
        "colab_type": "text"
      },
      "source": [
        "Возьмём четыре тысячи наиболее частых иероглифов (на сайте они выстроены по частоте), потому что все сразу брать смысла нет."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpWXZQm4CQzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page = sess.get('http://www.hanzicraft.com/lists/frequency')\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "hanzi = [ch.text.strip().split('\\n')[0] for ch in soup.findAll('li', class_='list')][:4000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K282_wTJCQzY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fbbb7a7e-d480-4ef0-b4dc-e09a68215e94"
      },
      "source": [
        "len(hanzi)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sdSIrv8CQzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hanzi_set = set(hanzi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ0az1QnCQzl",
        "colab_type": "text"
      },
      "source": [
        "Загрузим данные."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYTkF6JzCQzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from conllu import parse\n",
        "import urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nywXDovlFTtQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4ab04c7f-f8e4-4819-f0b6-b776734e0b59"
      },
      "source": [
        "train_url = 'https://raw.githubusercontent.com/UniversalDependencies/UD_Chinese-GSD/master/zh_gsd-ud-train.conllu'\n",
        "urllib.request.urlretrieve(train_url, filename = 'zh_gsd-ud-train.conllu')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('zh_gsd-ud-train.conllu', <http.client.HTTPMessage at 0x7fdc02c6e940>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJaW3ayoCQzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"zh_gsd-ud-train.conllu\", \"r\", encoding=\"utf-8\") as f:\n",
        "    cntr = f.read()\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lny_pGa2CQz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chinese_train = parse(cntr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r7f8gGFCQz8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e2814ea4-73a6-4d9b-82ca-ce701372d167"
      },
      "source": [
        "chinese_train[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TokenList<看似, 簡單, ，, 只, 是, 二, 選, 一, 做, 決擇, ，, 但, 其實, 他們, 代表, 的, 是, 你, 周遭, 的, 親朋, 好友, ，, 試, 著, 給, 你, 不同, 的, 意見, ，, 但, 追根究底, ，, 最後, 決定, 的, 還是, 自己, 。>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcpqRfCGCQ0C",
        "colab_type": "text"
      },
      "source": [
        "Для обучения будем использовать bag of characters, поскольку для иероглифов это просто предельно важно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9ljr1N1CQ0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chinese_train_words = [[w['form'] for w in i] for i in chinese_train]\n",
        "chinese_train_postags = [[w['upostag'] for w in i] for i in chinese_train]\n",
        "train_data = [(chinese_train_words[i], chinese_train_postags[i]) for i in range(len(chinese_train))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLZU3-heCQ0P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "b081050a-858c-492f-b5c1-97109f889adf"
      },
      "source": [
        "chinese_train_words[3], chinese_train_postags[3], train_data[3]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['懷孕', '期', '為', '421', '至', '457', '日', '。'],\n",
              " ['VERB', 'PART', 'AUX', 'NUM', 'CCONJ', 'NUM', 'NOUN', 'PUNCT'],\n",
              " (['懷孕', '期', '為', '421', '至', '457', '日', '。'],\n",
              "  ['VERB', 'PART', 'AUX', 'NUM', 'CCONJ', 'NUM', 'NOUN', 'PUNCT']))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JcrUhqtCQ0V",
        "colab_type": "text"
      },
      "source": [
        "Для иероглифов используем bag of characters. В основном иероглифы в одном слове не будут встречаться дважды, и словарь иероглифов довольно ограничен, так что этот подход довольно эффективен."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dyYhpIcCQ0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def features_list(word):\n",
        "    features = [0] * 4000\n",
        "    for ch in word:\n",
        "        if isinstance(ch, int) and len(features) == 4000: # в таком случае это не иероглиф, а число. достаточно единожды.\n",
        "            features.append(1)     # для чисел отдельная категория и своя часть речи.\n",
        "        elif (not isinstance(ch, int)) and len(features) == 4000:\n",
        "            features.append(0)\n",
        "            \n",
        "        if ch in hanzi_set: # быстрее membership checking. если иероглиф есть в списке:\n",
        "            ind = hanzi.index(ch) # соответсвтующая позиция - 1\n",
        "            features[ind] = 1\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_0Zz4IqCQ0c",
        "colab_type": "text"
      },
      "source": [
        "Итого получаем на выходе вектор размерностью 4001: 4000 иероглифов + число/не число"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t11dKCp2CQ0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_sequence(seq): # слова как вектор с тем, какие иероглифы в нём содержатся\n",
        "    idxs = [features_list(w) for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28ZAVsUZCQ0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_tags(seq, tags_ix): # тэги по маппингу\n",
        "    idxs = [tags_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIHPSF2WCQ0n",
        "colab_type": "text"
      },
      "source": [
        "Построим таблицу POS тэгов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw5dBxwnCQ0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pos = [dic['upostag'] for dic in sum(chinese_train, [])] # какие части речи есть в тренировочном корпусе? их и метим"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiIMT9rPCQ0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textlabels = list(set(train_pos))\n",
        "tag_to_ix = {}\n",
        "for i in range(len(textlabels)):\n",
        "    tag_to_ix[textlabels[i]] = i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdjdyPSOCQ0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "eab94b7a-ef74-4554-a8b0-5771766f98cb"
      },
      "source": [
        "tag_to_ix"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ADJ': 7,\n",
              " 'ADP': 13,\n",
              " 'ADV': 14,\n",
              " 'AUX': 3,\n",
              " 'CCONJ': 0,\n",
              " 'DET': 6,\n",
              " 'NOUN': 5,\n",
              " 'NUM': 10,\n",
              " 'PART': 1,\n",
              " 'PRON': 4,\n",
              " 'PROPN': 11,\n",
              " 'PUNCT': 9,\n",
              " 'SYM': 8,\n",
              " 'VERB': 2,\n",
              " 'X': 12}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA2ghKSJCQ00",
        "colab_type": "text"
      },
      "source": [
        "Получим тестовые данные."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVPzn9bEGBEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "66fcd9e6-5e1c-4e0a-87f3-1618aa8a7d38"
      },
      "source": [
        "test_url = 'https://raw.githubusercontent.com/UniversalDependencies/UD_Chinese-GSD/master/zh_gsd-ud-test.conllu'\n",
        "urllib.request.urlretrieve(test_url, filename = 'zh_gsd-ud-test.conllu')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('zh_gsd-ud-test.conllu', <http.client.HTTPMessage at 0x7fdbf7bdef28>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4VlTOQwCQ02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"zh_gsd-ud-test.conllu\", \"r\", encoding=\"utf-8\") as f: #https://github.com/UniversalDependencies/UD_Chinese-GSD\n",
        "    cntst = f.read()\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9P91D6YCQ05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chinese_test = parse(cntst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A74QHzurCQ0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chinese_test_words = [[w['form'] for w in i] for i in chinese_test]\n",
        "chinese_test_postags = [[w['upostag'] for w in i] for i in chinese_test]\n",
        "test_data = [(chinese_test_words[i], chinese_test_postags[i]) for i in range(len(chinese_test))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6p8T_L7fCQ1C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37fda324-00d4-4b73-c9ca-294181fc6166"
      },
      "source": [
        "chinese_test_words[2], chinese_test_postags[2], test_data[2]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['杜鵑花',\n",
              "  '為',\n",
              "  '溫帶',\n",
              "  '植物',\n",
              "  '，',\n",
              "  '台北',\n",
              "  '雖然',\n",
              "  '在',\n",
              "  '亞',\n",
              "  '熱帶',\n",
              "  '，',\n",
              "  '但',\n",
              "  '冬季',\n",
              "  '的',\n",
              "  '東北',\n",
              "  '季風',\n",
              "  '卻',\n",
              "  '使得',\n",
              "  '杜鵑花',\n",
              "  '在',\n",
              "  '臺大',\n",
              "  '宜然自得',\n",
              "  '。'],\n",
              " ['NOUN',\n",
              "  'AUX',\n",
              "  'NOUN',\n",
              "  'NOUN',\n",
              "  'PUNCT',\n",
              "  'PROPN',\n",
              "  'ADP',\n",
              "  'VERB',\n",
              "  'PART',\n",
              "  'NOUN',\n",
              "  'PUNCT',\n",
              "  'ADV',\n",
              "  'NOUN',\n",
              "  'PART',\n",
              "  'NOUN',\n",
              "  'NOUN',\n",
              "  'ADV',\n",
              "  'VERB',\n",
              "  'NOUN',\n",
              "  'VERB',\n",
              "  'PROPN',\n",
              "  'VERB',\n",
              "  'PUNCT'],\n",
              " (['杜鵑花',\n",
              "   '為',\n",
              "   '溫帶',\n",
              "   '植物',\n",
              "   '，',\n",
              "   '台北',\n",
              "   '雖然',\n",
              "   '在',\n",
              "   '亞',\n",
              "   '熱帶',\n",
              "   '，',\n",
              "   '但',\n",
              "   '冬季',\n",
              "   '的',\n",
              "   '東北',\n",
              "   '季風',\n",
              "   '卻',\n",
              "   '使得',\n",
              "   '杜鵑花',\n",
              "   '在',\n",
              "   '臺大',\n",
              "   '宜然自得',\n",
              "   '。'],\n",
              "  ['NOUN',\n",
              "   'AUX',\n",
              "   'NOUN',\n",
              "   'NOUN',\n",
              "   'PUNCT',\n",
              "   'PROPN',\n",
              "   'ADP',\n",
              "   'VERB',\n",
              "   'PART',\n",
              "   'NOUN',\n",
              "   'PUNCT',\n",
              "   'ADV',\n",
              "   'NOUN',\n",
              "   'PART',\n",
              "   'NOUN',\n",
              "   'NOUN',\n",
              "   'ADV',\n",
              "   'VERB',\n",
              "   'NOUN',\n",
              "   'VERB',\n",
              "   'PROPN',\n",
              "   'VERB',\n",
              "   'PUNCT']))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfX1upg5CQ1H",
        "colab_type": "text"
      },
      "source": [
        "Приступим к питорчу"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78_44sqlCQ1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGlrnSxpCQ1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 4001\n",
        "HIDDEN_DIM = 64\n",
        "VOCAB_SIZE = 4001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vL5tR20CQ1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        lstm_out, _ = self.lstm(sentence.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG2y5CViCQ1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, len(tag_to_ix))\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2G-rQyPbCQ1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03c34ffe-9647-43ca-bd13-1b46a3fff01c"
      },
      "source": [
        "with torch.no_grad(): # scores before training\n",
        "    inputs = prepare_sequence(train_data[0][0])\n",
        "    tag_scores = model(inputs)\n",
        "    print(tag_scores)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.6452, -2.6986, -2.6694, -2.8301, -2.6916, -2.6713, -2.6924, -2.6595,\n",
            "         -2.8458, -2.8378, -2.6700, -2.7204, -2.6561, -2.6917, -2.6730],\n",
            "        [-2.6313, -2.7044, -2.6788, -2.8350, -2.6839, -2.6624, -2.6960, -2.6734,\n",
            "         -2.8481, -2.8448, -2.6687, -2.7158, -2.6709, -2.6760, -2.6656],\n",
            "        [-2.6259, -2.7099, -2.6858, -2.8368, -2.6808, -2.6581, -2.6996, -2.6795,\n",
            "         -2.8496, -2.8455, -2.6653, -2.7131, -2.6767, -2.6700, -2.6598],\n",
            "        [-2.6185, -2.7222, -2.7185, -2.8488, -2.6978, -2.6541, -2.6962, -2.6770,\n",
            "         -2.8507, -2.8258, -2.6432, -2.6856, -2.6823, -2.6739, -2.6628],\n",
            "        [-2.6202, -2.7066, -2.7130, -2.8564, -2.6814, -2.6631, -2.7071, -2.6863,\n",
            "         -2.8558, -2.8438, -2.6456, -2.6884, -2.6705, -2.6699, -2.6533],\n",
            "        [-2.6141, -2.7175, -2.7030, -2.8527, -2.6984, -2.6710, -2.6900, -2.6947,\n",
            "         -2.8595, -2.8321, -2.6419, -2.6778, -2.6766, -2.6848, -2.6459],\n",
            "        [-2.6176, -2.7172, -2.7008, -2.8454, -2.6930, -2.6608, -2.6953, -2.6920,\n",
            "         -2.8561, -2.8363, -2.6496, -2.6934, -2.6781, -2.6767, -2.6462],\n",
            "        [-2.6243, -2.7234, -2.6894, -2.8525, -2.6914, -2.6664, -2.7000, -2.6790,\n",
            "         -2.8510, -2.8274, -2.6538, -2.7028, -2.6776, -2.6721, -2.6462],\n",
            "        [-2.6199, -2.7088, -2.6899, -2.8532, -2.6836, -2.6768, -2.7009, -2.6778,\n",
            "         -2.8443, -2.8367, -2.6508, -2.7123, -2.6887, -2.6780, -2.6363],\n",
            "        [-2.6184, -2.7111, -2.6945, -2.8453, -2.6814, -2.6666, -2.7020, -2.6817,\n",
            "         -2.8498, -2.8386, -2.6550, -2.7084, -2.6889, -2.6743, -2.6417],\n",
            "        [-2.6184, -2.7137, -2.6957, -2.8418, -2.6815, -2.6605, -2.7023, -2.6828,\n",
            "         -2.8519, -2.8399, -2.6560, -2.7078, -2.6887, -2.6722, -2.6445],\n",
            "        [-2.6091, -2.7207, -2.6922, -2.8253, -2.6950, -2.6439, -2.6905, -2.6974,\n",
            "         -2.8620, -2.8457, -2.6584, -2.7146, -2.6835, -2.6750, -2.6462],\n",
            "        [-2.6169, -2.7105, -2.6888, -2.8390, -2.7050, -2.6583, -2.6833, -2.6849,\n",
            "         -2.8654, -2.8424, -2.6527, -2.7146, -2.6713, -2.6626, -2.6644],\n",
            "        [-2.6141, -2.7275, -2.7021, -2.8277, -2.7065, -2.6511, -2.6946, -2.6816,\n",
            "         -2.8668, -2.8290, -2.6691, -2.7113, -2.6654, -2.6651, -2.6462],\n",
            "        [-2.6264, -2.7395, -2.6887, -2.8269, -2.6931, -2.6273, -2.6872, -2.6943,\n",
            "         -2.8635, -2.8191, -2.6644, -2.7170, -2.6807, -2.6684, -2.6597],\n",
            "        [-2.6271, -2.7168, -2.6891, -2.8479, -2.6964, -2.6492, -2.6838, -2.7034,\n",
            "         -2.8474, -2.8418, -2.6597, -2.7017, -2.6788, -2.6746, -2.6405],\n",
            "        [-2.6209, -2.7009, -2.6984, -2.8562, -2.6818, -2.6633, -2.7056, -2.6982,\n",
            "         -2.8506, -2.8487, -2.6545, -2.6930, -2.6729, -2.6727, -2.6430],\n",
            "        [-2.6233, -2.7009, -2.6949, -2.8392, -2.6881, -2.6439, -2.7100, -2.6914,\n",
            "         -2.8676, -2.8403, -2.6571, -2.7016, -2.6899, -2.6612, -2.6505],\n",
            "        [-2.6332, -2.7437, -2.7189, -2.8494, -2.7206, -2.6275, -2.6775, -2.6674,\n",
            "         -2.8662, -2.8358, -2.6428, -2.7190, -2.6732, -2.6519, -2.6382],\n",
            "        [-2.6323, -2.7222, -2.7054, -2.8571, -2.7092, -2.6446, -2.6852, -2.6938,\n",
            "         -2.8468, -2.8466, -2.6492, -2.7043, -2.6723, -2.6647, -2.6281],\n",
            "        [-2.6252, -2.7199, -2.6999, -2.8475, -2.7020, -2.6470, -2.6897, -2.6909,\n",
            "         -2.8478, -2.8433, -2.6506, -2.7054, -2.6760, -2.6731, -2.6407],\n",
            "        [-2.6387, -2.7076, -2.6430, -2.8089, -2.6759, -2.6588, -2.7306, -2.7099,\n",
            "         -2.8428, -2.8357, -2.6475, -2.7124, -2.6916, -2.6807, -2.6679],\n",
            "        [-2.6308, -2.7096, -2.6639, -2.8238, -2.6842, -2.6558, -2.7145, -2.6937,\n",
            "         -2.8488, -2.8402, -2.6553, -2.7137, -2.6874, -2.6737, -2.6589],\n",
            "        [-2.6264, -2.7116, -2.6762, -2.8316, -2.6849, -2.6552, -2.7078, -2.6870,\n",
            "         -2.8515, -2.8423, -2.6569, -2.7138, -2.6856, -2.6703, -2.6551],\n",
            "        [-2.6239, -2.7130, -2.6834, -2.8360, -2.6847, -2.6548, -2.7045, -2.6845,\n",
            "         -2.8528, -2.8429, -2.6571, -2.7129, -2.6850, -2.6687, -2.6532],\n",
            "        [-2.6225, -2.7140, -2.6876, -2.8385, -2.6843, -2.6544, -2.7029, -2.6835,\n",
            "         -2.8534, -2.8429, -2.6569, -2.7120, -2.6848, -2.6680, -2.6521],\n",
            "        [-2.6244, -2.7080, -2.6889, -2.8301, -2.6880, -2.6385, -2.7076, -2.6820,\n",
            "         -2.8709, -2.8399, -2.6594, -2.7138, -2.6948, -2.6566, -2.6569],\n",
            "        [-2.6175, -2.7189, -2.6941, -2.8191, -2.6928, -2.6583, -2.7219, -2.6817,\n",
            "         -2.8764, -2.8355, -2.6446, -2.7069, -2.6644, -2.6840, -2.6436],\n",
            "        [-2.6178, -2.7094, -2.6940, -2.8421, -2.6898, -2.6627, -2.7049, -2.7004,\n",
            "         -2.8532, -2.8483, -2.6517, -2.6964, -2.6717, -2.6865, -2.6312],\n",
            "        [-2.6132, -2.7128, -2.6868, -2.8412, -2.6883, -2.6430, -2.7142, -2.6971,\n",
            "         -2.8336, -2.8498, -2.6449, -2.7007, -2.6926, -2.6855, -2.6540],\n",
            "        [-2.6160, -2.7161, -2.6879, -2.8427, -2.6842, -2.6484, -2.7086, -2.6902,\n",
            "         -2.8423, -2.8446, -2.6551, -2.7028, -2.6890, -2.6776, -2.6520],\n",
            "        [-2.6073, -2.7229, -2.6870, -2.8273, -2.6952, -2.6374, -2.6937, -2.7008,\n",
            "         -2.8570, -2.8481, -2.6602, -2.7122, -2.6821, -2.6772, -2.6509],\n",
            "        [-2.6400, -2.7246, -2.6421, -2.8162, -2.6951, -2.5987, -2.7044, -2.6980,\n",
            "         -2.8330, -2.8567, -2.7035, -2.7407, -2.6854, -2.6647, -2.6555],\n",
            "        [-2.6278, -2.7189, -2.6686, -2.8264, -2.6922, -2.6253, -2.6978, -2.6915,\n",
            "         -2.8393, -2.8491, -2.6831, -2.7274, -2.6851, -2.6697, -2.6541],\n",
            "        [-2.6417, -2.7184, -2.6837, -2.8339, -2.6878, -2.6461, -2.7137, -2.6859,\n",
            "         -2.8432, -2.8296, -2.6855, -2.7218, -2.6757, -2.6463, -2.6410],\n",
            "        [-2.6256, -2.7203, -2.7086, -2.8405, -2.6936, -2.6563, -2.7043, -2.6887,\n",
            "         -2.8404, -2.8393, -2.6628, -2.7126, -2.6603, -2.6585, -2.6446],\n",
            "        [-2.6254, -2.7105, -2.6989, -2.8529, -2.6894, -2.6597, -2.6941, -2.7023,\n",
            "         -2.8354, -2.8556, -2.6612, -2.6979, -2.6660, -2.6747, -2.6353],\n",
            "        [-2.6202, -2.6991, -2.7041, -2.8582, -2.6753, -2.6666, -2.7102, -2.6971,\n",
            "         -2.8450, -2.8574, -2.6577, -2.6913, -2.6646, -2.6738, -2.6413],\n",
            "        [-2.6157, -2.6979, -2.7158, -2.8502, -2.6965, -2.6693, -2.6921, -2.6772,\n",
            "         -2.8508, -2.8539, -2.6692, -2.6829, -2.6638, -2.6717, -2.6535],\n",
            "        [-2.6207, -2.7055, -2.7021, -2.8463, -2.6908, -2.6627, -2.6964, -2.6811,\n",
            "         -2.8548, -2.8501, -2.6597, -2.6985, -2.6742, -2.6670, -2.6500]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OGSLCxQCQ1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFaA5oPpCQ1i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "9d255cb8-cdba-454b-d429-47c8f93da2d0"
      },
      "source": [
        "for epoch in range(epochs):  # again, normally you would NOT do 300 epochs, it is toy data\n",
        "    for sentence, tags in tqdm(train_data):\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
        "        # Tensors of word indices.\n",
        "        sentence_in = prepare_sequence(sentence)\n",
        "        targets = prepare_tags(tags, tag_to_ix)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        tag_scores = model(sentence_in)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        #  calling optimizer.step()\n",
        "        loss = loss_function(tag_scores, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print('Epoch {} has passed'.format(str(epoch+1)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3997/3997 [01:06<00:00, 60.11it/s]\n",
            "  0%|          | 7/3997 [00:00<01:09, 57.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 has passed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3997/3997 [01:06<00:00, 60.47it/s]\n",
            "  0%|          | 6/3997 [00:00<01:07, 59.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 has passed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3997/3997 [01:04<00:00, 62.36it/s]\n",
            "  0%|          | 7/3997 [00:00<01:09, 57.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 has passed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3997/3997 [01:05<00:00, 62.05it/s]\n",
            "  0%|          | 7/3997 [00:00<01:11, 55.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4 has passed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3997/3997 [01:05<00:00, 60.63it/s]\n",
            "  0%|          | 7/3997 [00:00<01:12, 55.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5 has passed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3997/3997 [01:05<00:00, 61.03it/s]\n",
            "  0%|          | 7/3997 [00:00<01:08, 58.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6 has passed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3997/3997 [01:05<00:00, 61.42it/s]\n",
            "  0%|          | 7/3997 [00:00<01:09, 57.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7 has passed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3997/3997 [01:05<00:00, 60.91it/s]\n",
            "  0%|          | 5/3997 [00:00<01:22, 48.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8 has passed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3997/3997 [01:06<00:00, 60.32it/s]\n",
            "  0%|          | 6/3997 [00:00<01:12, 55.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9 has passed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3997/3997 [01:05<00:00, 59.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10 has passed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJzXGnL_CQ1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "43dca265-f076-4dd7-946c-d28f6120efbd"
      },
      "source": [
        "with torch.no_grad():\n",
        "    inputs = prepare_sequence(train_data[0][0])\n",
        "    tag_scores = model(inputs)\n",
        "\n",
        "    print(tag_scores[0]) # максимальное значение в тензоре соответствует предсказанной POS"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ -9.9266, -10.9005,  -0.0656,  -5.5113,  -8.1226,  -4.4142,  -5.6757,\n",
            "         -3.6999,  -9.5186,  -9.9690,  -6.3908,  -5.2723,  -7.8330,  -5.6646,\n",
            "         -4.8286])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHrQHunLCQ1w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7067ae21-94ab-481f-c71d-d696198498b6"
      },
      "source": [
        "tags_predicted = []\n",
        "tags_true = []\n",
        "for d in tqdm(test_data):\n",
        "    with torch.no_grad():\n",
        "\n",
        "        tags = prepare_tags(d[1], tag_to_ix)\n",
        "        tags_true.append(tags.tolist())\n",
        "        \n",
        "        inputs = prepare_sequence(d[0])\n",
        "        tag_scores = model(inputs).tolist()\n",
        "        tags_encoded = [i.index(max(i)) for i in tag_scores] # максимальное значение в тензоре соответствует предсказанной POS\n",
        "        tags_predicted.append(tags_encoded)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:02<00:00, 168.20it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM8PfsTnCQ10",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8ca71264-e48b-4a50-a3fa-68a03fb47a47"
      },
      "source": [
        "tags_predicted[0], tags_true[0]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([14, 9, 2, 1, 5, 14, 2, 1, 7, 5, 5], [14, 9, 4, 1, 5, 14, 2, 1, 7, 5, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScQ3VSiBCQ1-",
        "colab_type": "text"
      },
      "source": [
        "Для глобальной статистики мы можем и unnestн'уть списки. Это поможет определить, какие части речи определились правильно, а какие - нет."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdnJdnsCCQ2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags_pred = sum(tags_predicted, [])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxoIwzpqCQ2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags_actual = sum(tags_true, [])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNjB4qzPCQ2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgROjxCMCQ2M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ec70028f-1d37-428e-9880-e7f79cfa936c"
      },
      "source": [
        "f1_score(tags_actual, tags_pred, average='micro')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6704129204129204"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExLHtXTqCQ2Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "df750366-f3c4-4dfc-caaa-2adada3a67c3"
      },
      "source": [
        "accuracy_score(tags_actual, tags_pred)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6704129204129204"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt5xtO1HCQ2u",
        "colab_type": "text"
      },
      "source": [
        "'PART': 0,\n",
        " 'SYM': 1,\n",
        " 'ADP': 2,\n",
        " 'ADJ': 3,\n",
        " 'NOUN': 4,\n",
        " 'CCONJ': 5,\n",
        " 'DET': 6,\n",
        " 'VERB': 7,\n",
        " 'PRON': 8,\n",
        " 'X': 9,\n",
        " 'NUM': 10,\n",
        " 'PUNCT': 11,\n",
        " 'ADV': 12,\n",
        " 'AUX': 13,\n",
        " 'PROPN': 14"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icktmASmCQ2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "6c2bd839-fb2b-4e98-d09d-bc7370ab9edc"
      },
      "source": [
        "confusion_matrix(tags_actual, tags_pred)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 140,    3,   11,    1,    0,    3,    0,    0,    0,   21,    0,\n",
              "           0,    0,    5,    7],\n",
              "       [   0,  900,   27,    2,    0,  218,    0,    4,    0,  160,   22,\n",
              "          19,    0,    1,    6],\n",
              "       [   1,   19, 1185,   23,    1,  236,    4,   11,    0,  139,   55,\n",
              "          27,    0,   43,   25],\n",
              "       [   0,    2,   44,  157,    0,    7,    0,    3,    0,   45,   12,\n",
              "           1,    0,    0,   10],\n",
              "       [   0,    1,    1,    0,  147,    4,    2,    0,    0,    4,    9,\n",
              "           0,    0,    0,    0],\n",
              "       [   0,   81,  253,    4,    3, 2452,   10,   15,    0,  216,   97,\n",
              "         146,    0,   23,   12],\n",
              "       [   0,    3,    6,    0,   14,   15,   60,    2,    0,    8,   26,\n",
              "           0,    0,    2,    2],\n",
              "       [   1,    3,   32,    1,    0,   75,    0,   88,    0,   16,   24,\n",
              "           6,    0,    1,   25],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    3,    0,\n",
              "           0,    0,    0,    0],\n",
              "       [   0,   43,  135,    0,    0,  170,    0,    0,    0, 1185,  131,\n",
              "          16,    0,    7,    1],\n",
              "       [   0,    6,   18,    2,    0,   46,    0,    0,    0,   88,  478,\n",
              "          14,    0,    0,    1],\n",
              "       [   1,   14,   35,    0,    0,  144,    1,    8,    0,   41,   31,\n",
              "         725,    0,    5,    1],\n",
              "       [   0,    1,   11,    0,    0,   13,    0,    0,    0,   38,   21,\n",
              "           4,    0,    0,    0],\n",
              "       [   8,   11,  108,    0,    2,   48,    0,    0,    0,  104,   25,\n",
              "           7,    0,  213,    9],\n",
              "       [   2,    3,   51,    6,    0,   49,    3,   27,    0,   48,   19,\n",
              "           7,    0,   11,  323]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExUfcKRWCQ26",
        "colab_type": "text"
      },
      "source": [
        "Для пяти эпох результаты очень хорошие. Это говорит об эффективности модели Bag of Characters для сильно основанного на иероглифах китайского языка!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2AN46duCQ3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}